\section{Threat Model and Security Analysis}
\label{sec:security_analysis}

The security of \textsc{AC-BlockDFL} rests on mitigating sophisticated, economically-driven vulnerabilities while maintaining committee-scale efficiency. In this section, we formalize the adversary model, define the Progressive Committee Capture Attack (PCCA), and establish the dual-layer security guarantees and game-theoretic incentive compatibility of our framework.

\subsection{Threat Model and Adversary Capabilities}
\label{sec:threat_model}

Unlike traditional Byzantine fault tolerance research that assumes purely destructive behavior, our threat model considers a \emph{Rational Adversary} whose primary objective is long-term economic utility maximization and governance control. This aligns with realistic blockchain incentive structures. 

\paragraph{Capabilities.} The adversary controls a fraction of the network nodes, denoted by $f$, where typically $f \leq 0.3$. These malicious nodes are not isolated; they can collude, coordinate voting strategies, and share information. Crucially, the adversary is highly strategic: malicious nodes can perfectly emulate honest behavior to build reputation and accumulate resources during early stages, instantly switching to malicious actions when an advantageous opportunity arises. Furthermore, the adversary has full visibility into the public blockchain state, including stake distributions and historical committee components.

\paragraph{Limitations.} The adversary is constrained by standard cryptographic assumptions (e.g., unforgeable digital signatures, collision-resistant hash functions) and cannot tamper with immutable historical records on the blockchain. Furthermore, the adversary cannot command an absolute network majority (e.g., $>50\%$) due to the prohibitively high capital costs. Finally, their actions are governed by economic rationality; they will not execute attacks where the expected financial penalty strictly outweighs the potential gains.

\subsection{Progressive Committee Capture Attack (PCCA)}
\label{sec:pcca}

Current BlockDFL defenses overwhelmingly focus on data-plane attacks (e.g., data poisoning), relying on robust aggregation algorithms like Krum~\cite{blanchard2017machine} or Trimmed Mean~\cite{yin2018byzantine}. However, these algorithms implicitly assume that the validators executing them are honest. We formalize the \emph{Progressive Committee Capture Attack (PCCA)}, a consensus-plane vulnerability that exploits the positive feedback loop of stake-based committee selections: ``Stake $\rightarrow$ Election $\rightarrow$ Reward $\rightarrow$ Stake''. By subverting the committee, PCCA enables attackers to entirely bypass data-plane defenses. The attack unfolds in two distinct phases:

\paragraph{Phase 1: Lurking (Shadow Mode).}
Because committee selection relies on stake-weighted random sampling, gaining a majority requires significant capital or chance. In this phase, the adversary strictly adheres to protocol rules---submitting high-quality model updates and verifying proposals honestly. This patience allows the adversary to accumulate baseline stake and evade anomaly detection. The adversary waits for a serendipitous election window where malicious nodes coincidentally obtain a supermajority (e.g., $>2/3$) of the seats in a single committee.

\paragraph{Phase 2: Occupying (Capture Mode).}
Upon securing a committee supermajority, the adversary drops the honest facade. The specific execution depends on the alignment of the current round's aggregator:
\begin{itemize}
    \item \textbf{Strategic Starvation}: If the aggregator is honest, the malicious committee executes a denial-of-service by systematically voting against valid, high-quality proposals. Consequently, honest aggregators and data providers are denied their block rewards. This starvation stunts the stake growth of honest participants, mathematically guaranteeing that the adversary captures a disproportionately larger share of the systemic inflation. Over successive rounds, this inflates the adversary's probability of being selected for future committees.
    \item \textbf{Full Stack Poisoning}: If the aggregator is also controlled by the adversary, they achieve ``full-stack control.'' The malicious aggregator deliberately accepts poisoned model updates (e.g., backdoor triggers or flipped labels), and the malicious committee force-approves the proposal. This directly degrades the global model's accuracy while monopolizing the round's rewards.
\end{itemize}

Through PCCA, the adversary's relative stake advantage over honest nodes dynamically shifts, converging to a steady-state advantage $\lim_{t \to \infty} \frac{S_{mal}(t)}{S_{hon}(t)} = \alpha \cdot \frac{S_{mal}(0)}{S_{hon}(0)}$ (where $\alpha > 1$ represents the reward control factor). This locks the system into a permanent governance imbalance, transforming a decentralized network into an oligarchy.

\subsection{Security Guarantees}
\label{sec:security_guarantees}

Our security model comprises two layers with distinct trust assumptions designed specifically to break the PCCA feedback loop: a \emph{detection layer} requiring only a single honest challenger, and an \emph{arbitration layer} leveraging standard Byzantine fault tolerance.

\paragraph{Detection Layer: 1-of-$N$ Honest Assumption.}
The detection layer operates under an exceptionally weak assumption: among all $N$ network participants, at least one honest node is willing to act as a challenger. This is substantially weaker than the $2/3$ honest majority required by traditional BFT systems, as it requires only the \emph{existence} of a single honest participant rather than coordinated action by a majority. The feasibility of this assumption stems from blockchain's transparency---all proposal CIDs are recorded on-chain with corresponding data publicly accessible via IPFS, enabling any node to independently verify committee decisions.

\begin{theorem}[Detection Completeness]
\label{thm:detection_completeness}
Let $\mathcal{V}_r$ denote the verification committee for round $r$, $\mathrm{Krum}(\{p_a\})$ be the deterministic correct result of executing Krum over all aggregation proposals, and $w_{r+1}$ be the global update actually committed by the committee. If $w_{r+1} \neq \mathrm{Krum}(\{p_a\})$ and there exists at least one honest node $c^*$ among all $N$ participants willing to act as challenger, then this deviation is necessarily detected.
\end{theorem}

\begin{proof}
The proof relies on Krum's determinism and the public verifiability of on-chain data. Given identical inputs $\{p_a\}$, any executor obtains the unique output $\mathrm{Krum}(\{p_a\})$ regardless of identity or location. Since all proposal CIDs are recorded on-chain during committee consensus and corresponding data is accessible via IPFS, the honest challenger $c^*$ can: (1) retrieve the identical input set $\{p_a\}$ from IPFS, (2) independently execute Krum locally to obtain $\mathrm{Krum}(\{p_a\})$, and (3) compare against the committed $w_{r+1}$. Any discrepancy constitutes verifiable proof of deviation, enabling $c^*$ to submit a valid challenge transaction. Since verification depends solely on publicly accessible on-chain CIDs, IPFS data, and deterministic computation, the committee cannot evade detection through information hiding or ambiguity.
\end{proof}

\paragraph{Arbitration Layer: Global $2/3$ Honest Assumption.}
When a challenge is initiated, adjudication authority transfers from the committee to the entire network under standard BFT assumptions: honest nodes must exceed $2/3$ of total nodes, i.e., $N_{\text{total}} > 3f$ where $f$ is the number of Byzantine nodes. During arbitration, all validators download relevant proposals via IPFS, re-execute Krum, and vote on challenge validity through PBFT consensus.

\begin{theorem}[Punishment Certainty]
\label{thm:punishment_certainty}
Let $N_{\text{total}}$ be the total network nodes with Byzantine count $f$ satisfying $N_{\text{total}} > 3f$. If a challenger successfully detects committee misbehavior per Theorem~\ref{thm:detection_completeness} and submits a valid challenge transaction, then the misbehavior is necessarily confirmed during arbitration, and all colluding committee members suffer complete stake slashing.
\end{theorem}

\begin{proof}
Upon challenge submission, the smart contract retrieves all proposal CIDs for the disputed round and triggers network-wide re-verification. By Krum's determinism, all honest validators compute identical correct results $\mathrm{Krum}(\{p_a\})$ and can determine whether $w_{r+1}$ deviates. Under $N_{\text{total}} > 3f$, at least $N_{\text{total}} - f > 2N_{\text{total}}/3$ honest nodes participate in arbitration voting. These honest nodes, based on identical deterministic computation, unanimously vote to confirm the deviation. Since PBFT requires $>2/3$ agreement and honest nodes exceed this threshold, arbitration consensus necessarily succeeds. The smart contract then automatically executes predefined slashing logic, confiscating the full stake of all committee members who endorsed the deviant result. This execution is guaranteed by smart contract determinism and immune to external interference.
\end{proof}

Theorems~\ref{thm:detection_completeness} and~\ref{thm:punishment_certainty} jointly establish the complete security logic: the former ensures misbehavior is \emph{necessarily discovered}, the latter ensures discovered misbehavior is \emph{necessarily punished}. This dual certainty forms the logical foundation for economic security.

\subsection{Cost of Attack}
\label{sec:attack_cost}

We now formalize the capital threshold an attacker must surpass to execute a profitable attack while evading punishment. Two distinct barriers must be overcome: (1) probabilistically winning $>2/3$ committee seats via random election, and (2) deterministically controlling $\geq 1/3$ of network voting power to block arbitration.

\begin{theorem}[Attack Cost Lower Bound]
\label{thm:attack_cost_bound}
In \textsc{AC-BlockDFL}, an attacker seeking to execute a malicious committee decision while completely evading economic punishment must control stake capital satisfying:
\begin{equation}
\mathrm{Cost}_{\mathrm{total}} \geq \frac{1}{3} N \cdot \bar{s}
\label{eq:attack_cost}
\end{equation}
where $N$ is the total network size and $\bar{s}$ is the average stake per node. Even with this capital, the attacker must still probabilistically obtain $>2/3$ committee seats through random election.
\end{theorem}

\begin{proof}
Achieving ``successful attack without punishment'' requires overcoming two security layers. At the committee level, the attacker must obtain $>2/3$ validator seats in the target round's random election---a probabilistic event determined by stake proportion that cannot be made certain. At the network level, per Theorem~\ref{thm:punishment_certainty}, once a challenge is initiated and verified, all malicious stakes are fully slashed. To evade punishment, the attacker must control $\geq \lceil N/3 \rceil$ of network voting power to break arbitration liveness by preventing PBFT consensus. This deterministic capital threshold scales linearly with network size as $O(N)$. Since punishment evasion is a logical prerequisite for profitable attack, the total attack cost lower bound is $\frac{1}{3} N \cdot \bar{s}$.
\end{proof}

This theorem reveals a fundamental security amplification: \textsc{AC-BlockDFL}'s asynchronous audit mechanism elevates the economic barrier from committee-scale $O(C)$ to network-scale $O(N)$. In traditional BlockDFL without post-hoc accountability, attack cost depends solely on controlling a small committee. \textsc{AC-BlockDFL} forces attackers to first solve the problem of countering a $2/3$ honest network majority before mounting any concrete attack. Given typical deployments where $N \gg C$ (e.g., $N=100$, $C=7$ in our experiments), this layered defense provides substantial robustness.

\subsection{Game-Theoretic Analysis}
\label{sec:game_theory}

We employ game-theoretic analysis to demonstrate that honest behavior constitutes the unique Nash equilibrium for all rational participants under \textsc{AC-BlockDFL}'s economic mechanism.

\paragraph{Attacker Payoff Model.}
For a rational attacker, the decision problem can be modeled as expected payoff computation in a single-shot game. Let $G_{\text{attack}}$ denote the maximum single-round gain from controlling the committee, and $L_{\text{slash}}$ the stake loss from full slashing. The expected payoff is:
\begin{equation}
E[\text{Payoff}] = P_{\text{success}} \cdot G_{\text{attack}} - P_{\text{caught}} \cdot L_{\text{slash}}
\label{eq:expected_payoff}
\end{equation}
where $P_{\text{success}}$ is the probability of controlling the committee in a given round, and $P_{\text{caught}}$ is the probability of detection and punishment. Note that $P_{\text{success}}$ measures election outcomes while $P_{\text{caught}}$ measures detection probability---distinct events at different layers. The attacker can only mount an attack when winning the election; once attacked, Theorems~\ref{thm:detection_completeness}--\ref{thm:punishment_certainty} ensure $P_{\text{caught}} \to 1$ under our dual-layer assumptions. Thus:
\begin{equation}
E[\text{Payoff}] = P_{\text{success}} \cdot (G_{\text{attack}} - L_{\text{slash}})
\label{eq:simplified_payoff}
\end{equation}

\paragraph{Incentive Compatibility Condition.}
The sufficient condition for incentive compatibility emerges clearly: whenever $L_{\text{slash}} > G_{\text{attack}}$, expected payoff is strictly negative regardless of $P_{\text{success}}$. Under our endogenous staking model, $L_{\text{slash}} = \lambda \times R_{\text{round}}$ while $G_{\text{attack}}$ is upper-bounded by $C \times R_{\text{round}}$ (monopolizing all validation rewards). Since $\lambda \gg C$ by design, this condition holds stably independent of token market fluctuations.

\paragraph{Numerical Analysis.}
Using our experimental parameters: committee size $C=7$, per-validator reward $1.0$ units, initial stake $100$ units. Maximum single-round gain $G_{\text{attack}} \leq 7.0$ units. Upon detection, at least 5 colluding members each lose their full 100-unit stake, yielding $L_{\text{slash}} = 500$ units---approximately $71\times$ the potential gain.

\begin{table}[t]
\centering
\caption{Attacker payoff matrix under \textsc{AC-BlockDFL}}
\label{tab:payoff_matrix}
\begin{tabular}{lcc}
\toprule
\textbf{Strategy} & \textbf{Gain} & \textbf{Loss (if detected)} \\
\midrule
Honest behavior & $R_{\text{round}}$ (proportional) & 0 \\
Attack (success) & $\leq 7.0$ units & $500$ units \\
\bottomrule
\end{tabular}
\end{table}

This extreme risk-reward asymmetry ensures negative expected payoff even under optimistic attacker assumptions. For $E[\text{Payoff}] < 0$, we require $P_{\text{caught}} > G_{\text{attack}}/L_{\text{slash}} \approx 1.4\%$. Our security theorems guarantee $P_{\text{caught}} \to 1$, far exceeding this minimal threshold.

\paragraph{Nash Equilibrium.}
Honest behavior constitutes the unique Nash equilibrium: no rational player can improve their payoff by unilaterally deviating to attack. The slashing mechanism breaks the positive feedback loop enabling gradual committee capture attacks~\cite{chiu2018incentive}---instead of accumulating stake through manipulation, attackers suffer substantial stake reduction, permanently eliminating their governance influence. This equilibrium remains stable across all token market conditions due to the endogenous stake pricing design.